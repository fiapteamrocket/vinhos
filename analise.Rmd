---
title: "Vinhos"
author: "FIAP-06IA - Carlos Martinelli, Jônatas Bertolazzo, Letticia Nicoli, Renato Ramos"
date: "6/18/2019"
output: html_document
---

## Dataset: Qualidade do Vinho 
Dataset realicionado com amostras de vinhos tintos e brancos do norte de Portugal. 
O objetivo é modelar a qualidade do vinho com base em testes físico-químicos.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
library(corrgram)
library(ggplot2)
library(rpart) 
library(rpart.plot)
library(plotly)
library(caret)
library(qcc)
library(ggplot2)
library(ggcorrplot)
library(scorecard)
library(cluster)
library(tclust)
library(outliers)
library(kableExtra)
red_color = "#E98383"
white_color = "#83E9D2"
cores = c(red_color, white_color)
```

```{r input, include=FALSE}
Vinhos <- read.csv2("G:/fiap/vinhos/BaseWine_Red_e_White.csv", row.names=1)


attach(Vinhos)
```

# Ánalise Exploratória

### Amostra do dataset
```{r echo=FALSE}
kable(head(Vinhos)) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

### Verifica se há preditores com variância próxima de zero
```{r}
nearZeroVar(Vinhos)
```
Não diagnosticamos preditores que possuam um valor exclusivo (ou seja, preditores de variação zero) ou preditores que possuam poucos valores exclusivos em relação ao número de amostras.

### Verifica se há valores ausentes (NAs)
```{r}
sapply(Vinhos, function(x)all(is.na(x)))
```
Observamos que não há nenhum valor ausente/faltante nesse dataset. Dessa forma, eliminamos a necessidade de tratar esses valores.

###  Resumo do dataset
```{r}
str(Vinhos)
```
O dataset possui 6497 observações de 13 variáveis.
Dentre essas observações a maioria são de vinhos brancos, conforme gráfico abaixo:

```{r}
summary(Vinhos)
```
Observamos que as variáveis `residualsugar`, `freesulfurdioxide` e `totalsulfurdioxide` possuem valores muito distantes entre mínimo e máximo. Isso pode indicar outliers e/ou desequilíbrio entre a quantidade de vinhos tintos e brancos, o que pode interferir nos resultados de classificação.

```{r echo=FALSE}
barplot(table(Vinho), col=c(red_color, white_color))
```

```{r echo=FALSE}
table(Vinho, quality)
```
Outro aspecto relevante é que a quantidade de vinhos brancos é maior do que vinhos tintos.
Apenas vinhos brancos possuem a nota máxima em relação a qualidade.

###  Correlação
Para realizar a correlação transformamos o campo `Vinho` (fator) para tipo numérico. Além de *normalizar* os dados para evitar algum tipo de distorção.

```{r echo=TRUE}
Vinhos$Vinho <- as.numeric(Vinhos$Vinho)
norm_vinhos <- scale(Vinhos)
```

Todos os Vinhos
```{r echo=FALSE}

matcor = cor(norm_vinhos)
ggcorrplot(matcor, hc.order = TRUE, 
           type = "lower", 
           lab = TRUE, 
           lab_size = 3, 
           method="circle", 
           colors = c("tomato2", "white", "springgreen3"), 
           title="Correlação dos Vinhos", 
           ggtheme=theme_dark)
```

```{r echo=FALSE}
corrgram(matcor, type = "cor", lower.panel = panel.shade, upper.panel = panel.pie)
```


Com o gráfico de correlação podemos observar que:

- O `alcool` tem uma correlação negativa alta com qualidade `desinty`
- O `freesulfurdioxide` tem uma correlação possitiva alta com`totalsulfurdioxide`

As outras correlações não são significativas no dataset


###  Ánalise de outliers

```{r echo=FALSE}
par (mfrow=c(1,3))

boxplot(fixedacidity ~ Vinho, main='fixedacidity',col=cores)
boxplot(volatileacidity ~ Vinho , main='volatileacidity',col=cores)
boxplot(citricacid ~ Vinho, main='citricacid',col=cores)
```

```{r echo=FALSE}
par (mfrow=c(1,3))
boxplot(residualsugar ~ Vinho, main='residualsugar',col=cores)
boxplot(chlorides ~ Vinho, main='chlorides',col=cores)
boxplot(freesulfurdioxide ~ Vinho, main='freesulfurdioxide' ,col=cores)

```

```{r echo=FALSE}
par (mfrow=c(1,3))
boxplot(totalsulfurdioxide ~ Vinho, main='totalsulfurdioxide',col=cores)
boxplot(density ~ Vinho, main='density',col=cores)
boxplot(pH ~ Vinho, main='pH',col=cores)
```

```{r echo=FALSE}
par (mfrow=c(1,3))
boxplot(sulphates ~ Vinho, main='sulphates',col=cores)
boxplot(alcohol ~ Vinho, main='alcohol',col=cores)
boxplot(quality ~ Vinho, main='quality', col=cores)
```

Com os gráficos acima pode-se observar que todas as variáveis possuem candidatos a outliers.
No dataset existem variáveis como `residualsugar` que possui o valor máximo muito acima do terceiro quartil, isso pode gerar distorções nos algoritmos que será executado a seguir. Alem disso há uma concentração de outliears nessas variáriveis, o que traz a necessidade de remove-los para evitar distorção nos passos seguintes

```{r}
VinhosOut = subset(Vinhos, subset = !(Vinhos$citricacid %in% boxplot.stats(Vinhos$citricacid)$out))
VinhosOut = subset(VinhosOut, subset = !(VinhosOut$residualsugar %in% boxplot.stats(VinhosOut$residualsugarsum)$out))
VinhosOut = subset(VinhosOut, subset = !(VinhosOut$freesulfurdioxide %in% boxplot.stats(VinhosOut$freesulfurdioxide)$out))
VinhosOut = subset(VinhosOut, subset = !(VinhosOut$totalsulfurdioxide %in% boxplot.stats(VinhosOut$totalsulfurdioxide)$out))

```

## Explicando a variável quality

### Preparação para separação de dados: treinamento e teste

```{r}
norm_vinhos = data.frame(norm_vinhos)
dt_list = split_df(norm_vinhos, ratio = 0.75, seed = 66)
train = dt_list$train
test = dt_list$test
```

Validando a consistência de qualidade entre as bases de treino e teste
```{r}
prop.table(table(train$quality))
```

```{r}
prop.table(table(test$quality))
```

As proporções estão, consideravelemente, bem distribuídas entre a qualidade. Dessa forma, conseguimos realizar um bom treinamento para o modelo.

### Regressão Linear

No primeiro modelo mantemos todas as varáveis:

```{r}

modelo1 <- lm(train$quality ~ train$fixedacidity+train$volatileacidity+
                train$citricacid+train$residualsugar+
                train$chlorides+train$freesulfurdioxide+train$totalsulfurdioxide+
                train$density+train$pH+train$sulphates+train$alcohol+
                train$Vinho)
summary(modelo1)

```

Nesse primeiro modelo a variável `citracid` não possui muita relevância pois o seu p-value está próximo a 1.
Para ter certeza sobre essa informação, utilizamos o método `stepwise` para identificar quais são as variáveis relavantes para o modelo.

```{r}
stepwise<-step(modelo1, direction="both")
summary(stepwise)

```
Como esperado, o método removeu a `citracid` do modelo.

Confiança desse modelo é de:
```{r}
confint(stepwise)
```

Modelo sem a variável de `citricidade`:
```{r}
modeloSemCitricidade <- lm(train$quality ~ train$fixedacidity + train$volatileacidity + train$residualsugar + train$freesulfurdioxide + train$density + train$pH + train$sulphates + train$alcohol)

summary(modeloSemCitricidade)  
```
O R-squared é de mais ou menos 30, o que significa que a regressão linear não descreve o modelo com tanta precisão.

Abaixo segue o modelo para base teste

```{r echo=TRUE}
modeloTestSemCitricidade <- lm(test$quality ~ test$fixedacidity + test$volatileacidity + test$residualsugar + test$freesulfurdioxide + test$density + test$pH + test$sulphates + test$alcohol)

summary(modeloTestSemCitricidade) 
```

O modelo criado através da técnica de regressão linear não descreve muito bem a nota de qualidade dos vinhos, com uma acertividade de aproximadamente 30%. Não será necessário fazer o modelo de predição, devido ao baixo índice de acertividade.

### Analise de resíduos

```{r echo=FALSE}
par(mfrow=c(2,2))
plot(modeloTestSemCitricidade)
```

Executando o teste de shapiro no modelo

```{r}
shapiro.test(residuals(modeloTestSemCitricidade))
```
Como o p-value ficou menor que 5 pode-se dizer que temos um modelo de regressão com pouca assertividade.

Isso corrobora com o valor d R-Quadrodo demonstrando que modelo não é assertivo.

### Arvore de Regressão

A seguir será executado a árvore de regressão para comparar com a regressão linear.
A árvore de regressão é um método de aprendizado supervisionado utilizado para tarefas de classificação e regressão.
A variável target é a quality e as variáveis que utilizaremos para prever o seu valor são: fixedacidity,  volatileacidity, citricacid, residualsugar, chlorides, freesulfurdioxide, totalsulfurdioxide, density,  pH,sulphates,alcohol.


```{r include=FALSE}
attach(train)
```


```{r echo=TRUE}
arvore_regressao = rpart (quality ~ fixedacidity + volatileacidity + citricacid + residualsugar + chlorides + freesulfurdioxide + totalsulfurdioxide + density + pH + sulphates + alcohol,
                      data=train, 
                      cp = 0.007,minsplit = 15, maxdepth=30)
```

```{r echo=TRUE}
rpart.plot(arvore_regressao, type=4, extra=1, under=FALSE, clip.right.labs=TRUE,
           fallen.leaves=FALSE,   digits=2, varlen=-10, faclen=20,
           cex=0.4, tweak=1.7,
           compress=TRUE, 
           snip=FALSE)
```

### Testando a árvore de regressão

Erro utilziando o modelo de árvore de regressão

```{r}
Val_pred_tree = predict(arvore_regressao,interval = "prediction", level = 0.95) 

mse_tree = mean((quality - Val_pred_tree)^2)
sqrt(mse_tree)
```

Erro utilizando média

```{r}
erro_usando_media = mean((train$quality - mean(train$quality))^2)
sqrt(erro_usando_media)
```

Pode-se dizer que o modelo de árvore de regressão é mais acertivo que o modelo de regressão linear.

E para árvore de regressão pode-se dizer que a quantide de alcool é fundamental para a qualidade do vinho seguindo de ácido volátil.

###Arvore de regressao sem outliers

#TODO

### Classificando dos Vinhos em Bom ou Ruim considerando a variável Qualidade

Adicionando a coluna de classificação dos vinhos

```{r include=FALSE}
vinhos_com_classificacao = VinhosOut
vinhos_com_classificacao$classificacao = ifelse(vinhos_com_classificacao$quality >= 6,  T, F)
dt_list_log = split_df(vinhos_com_classificacao, ratio = 0.75, seed = 66)
train_log = dt_list_log$train
test_log = dt_list_log$test
attach(train_log)
```

Executando o modelo com todos as variáveis

```{r}
modelo_logistico <- rpart (as.factor(classificacao) ~ fixedacidity+volatileacidity+citricacid+residualsugar+chlorides+freesulfurdioxide+totalsulfurdioxide+density+pH+sulphates+alcohol, maxdepth=20, train_log)
```

Resultado do modelo

```{r}
rpart.plot(modelo_logistico, type=5, extra=104, under=FALSE, clip.right.labs=TRUE,
           fallen.leaves=FALSE,
           digits=2, varlen=-8, faclen=10,
           cex=0.6, tweak=1,
           compress=TRUE,
           snip=FALSE)
```

### Testando o modelo

#### Matriz de confusão

```{r}
previsto.com.modelo<-predict(modelo_logistico, train_log, type='class')

matriz.de.confusao<-table(train_log$classificacao, previsto.com.modelo)
matriz.de.confusao
```

Calculando a diagonal da matriz

``` {r}
diagonal <- diag(matriz.de.confusao)
Acc <-  sum(diagonal)/sum(matriz.de.confusao)
Acc

```

Executando o algoritmo para base de testes

```{r}
#previsto.valid<-predict(modelo_logistico, test_log , type='class')

#test$previsto=previsto.valid
#test$classificacao <- ifelse(test$quality >= 6, T, F)
#test$errou = ifelse(test$previsto != test$classificacao, 1, 0)

```


Matriz de confusão para a base teste

```{r}
#previsto.com.modelo<-predict(modelo_logistico, test_log, type='class')

#matriz.de.confusao<-table(test_log$classificacao, previsto.com.modelo)
#matriz.de.confusao
```

Calculando a diagonal da matriz

``` {r}
#diagonal <- diag(matriz.de.confusao)
#Acc <-  sum(diagonal)/sum(matriz.de.confusao)
#Acc

```

### Clusterizando os Vinhos

Como técnica não supervisionada, vamos testar se o algoritmo de clusterização será adequado para agrupar dois conjunto de vinhos, categorizando-os como vinhos bons e vinhos ruins.
****A variável ‘quality’, que identifica a nota do vinho, será a variável utilizada para correlacionar com as demais variáveis para identificar se existe algum agrupamento entre os vinhos.

De acordo com Luis Costa de Oliveira, Sara Oliveira, Maria Eugenia em seu artigo 'Avaliação das características físico-químicas e colorimétricas de
vinhos finos de duas principais regiões vinícolas do Brasil ', a cor não é uma característica físico-química. 
***Portanto foram removidas as colunas de qualidade e tipo de vinho.

```{r}
vinhos_noColor <- norm_vinhos[1:11]
head(vinhos_noColor)
```

Utilizando o K-means para descobrir a quantidade ideal de clusters dentro de 10 iterações.

```{r}
wss = 0
#lets to k-means for 10 clusters 
for (i in 1:10) {
  wine_cluster <- kmeans(vinhos_noColor, centers = i)
  # Save total within sum of squares to wss variable
  wss[i] <- wine_cluster$tot.withinss
}
# Plot total within sum of squares vs. number of clusters
plot(1:10, wss, type = "b",  main="Elbow method",
     xlab = "Number of Clusters", 
     ylab = "Within groups sum of squares",pch=8, col="red")
```

Com base na plotagem, podemos determinar que, após o cluster 3, não vemos uma grande queda na soma das distâncias quadradas dentro de cada cluster, portanto, podemos considerar o valor de K como 3 e prosseguir com o agrupamento

### K-Means Segmentation
```{r}
k=3
w_cluster = kmeans(vinhos_noColor,  centers = k, nstart=20)
w_cluster
```

```{r}
#table(w_cluster$cluster, Vinhos$color)
```



```{r}
clus_teste <- tkmeans(vinhos_noColor , k = 3, alpha = 0.01)
plot(clus_teste)
```


```{r}
clusplot(vinhos_noColor, clus_teste$cluster, color=TRUE, shade=TRUE,
         labels=2, lines=0 , cex=0.75)
```

TODO: testar a normalizacao apenas das colunas maiores que 1
PCA?



























